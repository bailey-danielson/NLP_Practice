{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import text_reader\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(lines):\n",
    "    \"\"\"Remove numbers and punctuation, and standardize case\n",
    "\n",
    "    Keyword Arguments:\n",
    "    lines: string of text\"\"\"\n",
    "\n",
    "    # import\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # create set of stop words\n",
    "    stop = set(stopwords.words('english'))\n",
    "\n",
    "    lower_characters = lines.lower()\n",
    "    approved_words = []\n",
    "    white_list = set('abcdefghijklmnopqrstuvwxyz ')\n",
    "\n",
    "    for word in lower_characters.split():\n",
    "        if word not in stop:\n",
    "            clean_word = re.sub(r'[^a-z ]+', '', word)\n",
    "            approved_words.append(clean_word)\n",
    "    return approved_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_remove_stops(lines):\n",
    "    \"\"\"Remove numbers and punctuation, and standardize case\n",
    "\n",
    "    Keyword Arguments:\n",
    "    lines: string of text\"\"\"\n",
    "\n",
    "    # import\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # create set of stop words\n",
    "    stop = set(stopwords.words('english'))\n",
    "\n",
    "    lower_characters = lines.lower()\n",
    "    approved_words = []\n",
    "    white_list = set('abcdefghijklmnopqrstuvwxyz ')\n",
    "\n",
    "    for word in lower_characters.split():\n",
    "        if word not in stop:\n",
    "            clean_word = re.sub(r'[^a-z ]+', '', word)\n",
    "            approved_words.append(clean_word)\n",
    "    return \" \".join(approved_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words (model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/BaileyDanielson/Documents/Python/NLP_Practice/final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Section</th>\n",
       "      <th>Book_Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Index</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coetzee  In the Heart of the Country.</td>\n",
       "      <td>0</td>\n",
       "      <td>In the Heart of the Country</td>\n",
       "      <td>J.M. Coetzee</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today my father brought home his new bride.</td>\n",
       "      <td>1</td>\n",
       "      <td>In the Heart of the Country</td>\n",
       "      <td>J.M. Coetzee</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They came clip-clop across  the flats in a dog...</td>\n",
       "      <td>1</td>\n",
       "      <td>In the Heart of the Country</td>\n",
       "      <td>J.M. Coetzee</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Or perhaps they were drawn by two  plumed donk...</td>\n",
       "      <td>1</td>\n",
       "      <td>In the Heart of the Country</td>\n",
       "      <td>J.M. Coetzee</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My father wore his black swallowtail  coat and...</td>\n",
       "      <td>1</td>\n",
       "      <td>In the Heart of the Country</td>\n",
       "      <td>J.M. Coetzee</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.115079</td>\n",
       "      <td>0.239683</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Section  \\\n",
       "0              Coetzee  In the Heart of the Country.        0   \n",
       "1        Today my father brought home his new bride.        1   \n",
       "2  They came clip-clop across  the flats in a dog...        1   \n",
       "3  Or perhaps they were drawn by two  plumed donk...        1   \n",
       "4  My father wore his black swallowtail  coat and...        1   \n",
       "\n",
       "                    Book_Title        Author  Index  Polarity  Subjectivity  \\\n",
       "0  In the Heart of the Country  J.M. Coetzee      0  0.000000      0.000000   \n",
       "1  In the Heart of the Country  J.M. Coetzee      1  0.136364      0.454545   \n",
       "2  In the Heart of the Country  J.M. Coetzee      2 -0.225000      0.500000   \n",
       "3  In the Heart of the Country  J.M. Coetzee      3  0.000000      1.000000   \n",
       "4  In the Heart of the Country  J.M. Coetzee      4 -0.115079      0.239683   \n",
       "\n",
       "   Word_Count  \n",
       "0           7  \n",
       "1           8  \n",
       "2          25  \n",
       "3          13  \n",
       "4          24  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And then, for a third, there is the new wife, who lies late abed.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one book only: \n",
    "IHC_sentences = list(df[df[\"Book_Title\"] == \"In the Heart of the Country\"][\"Sentence\"])\n",
    "IHC_sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It wasn’t easy, for to me he looked old, impossibly old, and I could not remember him looking anything other than old – though, in  fact, at that time he could not have been much older than twenty-nine.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_sentences = list(df[df[\"Book_Title\"] == \"Shadow Lines\"][\"Sentence\"])\n",
    "SL_sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df[\"Sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And then, for a third, there is the new wife, who lies late abed.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'then third new wife lies late abed'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences = [clean_remove_stops(sent) for sent in sentences]\n",
    "clean_sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vector = vectorizer.fit_transform(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9558, 12059)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sent_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2, random_state=42)\n",
    "\n",
    "dtm_nmf = nmf.fit_transform(sent_vector)\n",
    "dtm_nmf = Normalizer(copy=False).fit_transform(dtm_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "would one like could back me see house time us room day it her perhaps old tridib way come go know ila say father away eyes tell him even never little look around much still think though head may man nothing face long must knew grandmother something people last them went then going two mother first told black came years later hands find road left world without hendrik end that whether words every now ever night door behind take hand looked get calcutta life didnt place used woman bed always days seemed moment another make hair often made myself home\n",
      "\n",
      "Topic #1:\n",
      "said ila dont know its me grandmother go may yes right tridib thats head it robi well im you voice now no come going nick that course father there oh little youre hand mrs told time here must then smiling cant remember ill mother turned theres first looking please old price look on wasnt nothing her tell much hes got face calcutta thing think us something didnt mayadebi later him see laughing take malik back story like ive shook everyone laughed eyes saifuddin long looked too place believe asked word heard whether gave really get though rehmanshaheb matter why hair\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, vectorizer.get_feature_names(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "IHC_clean = [clean_remove_stops(sent) for sent in IHC_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_clean = [clean_remove_stops(sent) for sent in SL_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "IHC_vector = vectorizer.fit_transform(IHC_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_vector = vectorizer.fit_transform(SL_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf1 = NMF(n_components=5, random_state=42)\n",
    "\n",
    "dtm1_nmf = nmf1.fit_transform(IHC_vector)\n",
    "dtm1_nmf = Normalizer(copy=False).fit_transform(dtm1_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "conakry lutfullah opposite lay jumps screens gazette statesman celebratory hid discovering kindness kissed barking curls label hostel floundering averted famine complaining stern calm edition halfhour officials ducked country alphabet alan\n",
      "\n",
      "Topic #1:\n",
      "inhabit step froze heater rushed bore provoke label edition sipping greying sombre screens been fragrance halfhour eighteenthcentury celebratory kindness inching bachao argument allowed forming indians storm arms pale backboneless betrayed\n",
      "\n",
      "Topic #2:\n",
      "stiff house been recalled scheme barking income church doubtful ducked dust sombre greying hundreds forks linger flown pale stay hotelier pealed soft fraud fuselage fuss schoolwork defeated saying medium pouting\n",
      "\n",
      "Topic #3:\n",
      "leading arms jumps halfhour santoshpur conakry sparkled intimacy jutting conceived inching saris idea step alphabet argument favourite bore say stay pealed leads edition feast majority squirmed saying indeterminate stern retired\n",
      "\n",
      "Topic #4:\n",
      "france allowed ducked storm doubtful bachao squirmed heater headdress curls arms sombre driver celebratory pealed ironic income lay averted palm splintered froze agent freeze failing ramna favourite rushed feel for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf1, vectorizer.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf2 = NMF(n_components=3, random_state=42)\n",
    "\n",
    "dtm2_nmf = nmf2.fit_transform(SL_vector)\n",
    "dtm2_nmf = Normalizer(copy=False).fit_transform(dtm2_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "could like back see tridib one us ila house her room time me tell way may around it old little much grandmother told father later go eyes know look went\n",
      "\n",
      "Topic #1:\n",
      "said dont its know go yes grandmother right thats ila im well robi no voice head me may you it now course come going oh that youre there father hand\n",
      "\n",
      "Topic #2:\n",
      "would say go often look grandmother people ask try knew going come think it sometimes him away wonder turn get house always whether every hurry hands find know first happened\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf2, vectorizer.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"would say go often look grandmother people ask try knew going come think it sometimes him away wonder turn get house always whether every hurry hands find know first happened\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
